{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tracking with MLFlow (Local)\n",
    "\n",
    "In this demo we will see how to use MLFlow for tracking experiments, using a toy data set. In the attached lab (below), you will download a larger dataset and attempt to train the best model that you can.\n",
    "\n",
    "We should first install mlflow, and add it to the requirements.txt file if not done already.\n",
    "\n",
    "`pip install mlflow` or `python3 -m pip install mlflow`.\n",
    "\n",
    "You may also need to `pip install setuptools`.\n",
    "\n",
    "From here, make sure to save this notebook in a specific folder, and ensure you run all command line commands from the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# import pandas as pd\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.datasets import load_wine\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the libraries, we can first check the mlflow version you have. And, just for fun, let's look at the mlflow UI by running `mlflow ui`. After this, we should do two things:\n",
    "- set the tracking uri\n",
    "- create or set the experiment\n",
    "\n",
    "Setting the tracking uri tells mlflow where to save the results of our experiments. We will first save these locally in a sqlite instance. In the next lab we will set up mlflow to run in GCP.\n",
    "\n",
    "If you've already created an experiment previously that you'd like to use, you can tell mlflow by setting the experiment. You can also use `set_experiment` even if the experiment has not yet been created - mlflow will first check if the experiment exists, and if not, it will create it for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the below code will create a sqlite database and an mlruns folder in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/tatshini/USF_School/DE/mlops/insyd_mlops/mlruns/1', creation_time=1725318818773, experiment_id='1', last_update_time=1725318818773, lifecycle_stage='active', name='price-prediction-experiment', tags={}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('sqlite:///../mlflow.db')\n",
    "mlflow.set_experiment('price-prediction-experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(inp):\n",
    "    for i in range(len(inp)):\n",
    "        try:\n",
    "            if type(inp[i]['price']) is str:\n",
    "                t = ''\n",
    "                for a in inp[i]['price']:\n",
    "                    if a in '0123456789':\n",
    "                        t += a\n",
    "                inp[i]['price'] = int(t)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            for a in inp[i]['features']:\n",
    "                s = a.split(' ')\n",
    "                if s[1] == 'm2':\n",
    "                    inp[i]['area'] = int(s[0])\n",
    "                elif s[1] == 'hab.':\n",
    "                    inp[i]['bed'] = int(s[0])\n",
    "                elif s[1] == 'ba\\u00f1o':\n",
    "                    inp[i]['bath'] = int(s[0])\n",
    "            del inp[i]['features']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \"\"\"\n",
    "        if 'aire acondicionado' in inp[i]['desc'].lower():\n",
    "            inp[i]['air_conditioning'] = True\n",
    "        else:\n",
    "            inp[i]['air_conditioning'] = False\n",
    "        if 'jardin' in inp[i]['desc'].lower() or 'jard\\u00edn' in inp[i]['desc'].lower():\n",
    "            inp[i]['garden'] = True\n",
    "        else:\n",
    "            inp[i]['garden'] = False\n",
    "        if 'parking' in inp[i]['desc'].lower():\n",
    "            inp[i]['parking'] = True\n",
    "        else:\n",
    "            inp[i]['parking'] = False\n",
    "        if 'galer\\u00edn' in inp[i]['desc'].lower():\n",
    "            inp[i]['gallery'] = True\n",
    "        else:\n",
    "            inp[i]['gallery'] = False\n",
    "        \"\"\"\n",
    "    df = pd.DataFrame(inp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('../data/train.pickle').expanduser()\n",
    "infile = open(file_path, 'rb')\n",
    "train = pickle.load(infile)\n",
    "infile.close()\n",
    "train_rf = reformat(train).dropna()\n",
    "file_path = Path('../data/test_kaggle.pickle').expanduser()\n",
    "infile = open(file_path, 'rb')\n",
    "test = pickle.load(infile)\n",
    "infile.close()\n",
    "y_train = train_rf['price']\n",
    "x_train = train_rf.drop('price', axis=1)\n",
    "x_test = reformat(test).drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.select_dtypes(exclude=['object'])\n",
    "x_test = x_test.select_dtypes(exclude=['object']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R^2 Score: 0.29313953268795934\n"
     ]
    }
   ],
   "source": [
    "model = sk.linear_model.LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "# Calculate R^2 score on the training set\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(\"Linear Regression R^2 Score:\", r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/f_k5y00n1p3d9f68vb9b7_7m0000gn/T/ipykernel_89402/2635635002.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col] = 0\n",
      "/var/folders/sy/f_k5y00n1p3d9f68vb9b7_7m0000gn/T/ipykernel_89402/2635635002.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col] = 0\n",
      "/var/folders/sy/f_k5y00n1p3d9f68vb9b7_7m0000gn/T/ipykernel_89402/2635635002.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col] = 0\n",
      "/var/folders/sy/f_k5y00n1p3d9f68vb9b7_7m0000gn/T/ipykernel_89402/2635635002.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col] = 0\n"
     ]
    }
   ],
   "source": [
    "file_path = Path('../data/train.pickle').expanduser()\n",
    "infile = open(file_path, 'rb')\n",
    "train = pickle.load(infile)\n",
    "infile.close()\n",
    "train_rf = reformat(train)\n",
    "file_path = Path('../data/test_kaggle.pickle').expanduser()\n",
    "infile = open(file_path, 'rb')\n",
    "test = pickle.load(infile)\n",
    "infile.close()\n",
    "test_rf = reformat(test)\n",
    "train = pd.DataFrame(train_rf)\n",
    "y_train = train['price']\n",
    "x_train = train.drop('price', axis=1)\n",
    "x_test = pd.DataFrame(test_rf).drop('id', axis=1)[x_train.columns]\n",
    "x_train = pd.get_dummies(x_train, columns=[\"loc_string\", \"loc\", \"type\", \"subtype\", \"selltype\"])\n",
    "x_test = pd.get_dummies(x_test, columns=[\"loc_string\", \"loc\", \"type\", \"subtype\", \"selltype\"])\n",
    "all_columns = set(x_train.columns)\n",
    "# Add any missing columns to the test dataset with values set to 0\n",
    "missing_columns = all_columns - set(x_test.columns)\n",
    "for col in missing_columns:\n",
    "    x_test[col] = 0\n",
    "# Reorder columns to match the order in the training dataset\n",
    "x_test = x_test[x_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"bath\"] = x_train[\"bath\"].fillna(1)\n",
    "x_train[\"bed\"] = x_train[\"bed\"].fillna(1)\n",
    "x_train[\"area\"] = x_train[\"area\"].fillna(int(x_train[\"area\"].mean()))\n",
    "x_test[\"bath\"] = x_test[\"bath\"].fillna(1)\n",
    "x_test[\"bed\"] = x_test[\"bed\"].fillna(1)\n",
    "x_test[\"area\"] = x_test[\"area\"].fillna(int(x_train[\"area\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = x_train.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_numeric_scaled = x_train.copy()\n",
    "x_train_numeric_scaled[numeric_columns] = scaler.fit_transform(x_train[numeric_columns])\n",
    "\n",
    "x_train_processed = pd.DataFrame(np.hstack((x_train_numeric_scaled[numeric_columns], x_train.select_dtypes(include=['object']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf_title', TfidfVectorizer(), 'title'),\n",
    "        ('tfidf_desc', TfidfVectorizer(), 'desc')\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = x_train.select_dtypes(exclude=['object']).columns.to_list() + x_train.select_dtypes(include=['object']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(x_train_processed.to_numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = x_test.select_dtypes(exclude=['object']).columns\n",
    "x_test_numeric_scaled = x_test.copy()\n",
    "x_test_numeric_scaled[numeric_columns] = scaler.transform(x_test[numeric_columns])\n",
    "\n",
    "x_test_processed = pd.DataFrame(np.hstack((x_test_numeric_scaled[numeric_columns], x_test.select_dtypes(include=['object']))))\n",
    "X_test = pd.DataFrame(x_test_processed.to_numpy(), columns=columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model Using MLFLow\n",
    "\n",
    "In this section, let's train a simple decision tree model, where we will now adjust the maximum depth (`max_depth`) of the tree, and save the results of each run of the experiment using mlflow. To do so, we need to tell mlflow to start recording. We do this with `start_run`. \n",
    "\n",
    "The things we might want to record in this simple case are:\n",
    "- the value of `max_depth`\n",
    "- the corresponding accuracy of the model\n",
    "\n",
    "We can also tag each run to make it easier to identify them later.\n",
    "\n",
    "After running the below code, be sure to check the mlflow UI by running the following in the terminal from the same directory as where you saved this notebook:\n",
    "\n",
    "`mlflow ui` note that just running this you will not see any of your experiments. You must specify the uri (the place where all of your results are being stored)\n",
    "\n",
    "`mlflow ui --backend-store-uri sqlite:///mlflow.db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "# Define models\n",
    "gb_model = make_pipeline(preprocessor, GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42))\n",
    "rf_model = make_pipeline(preprocessor, RandomForestRegressor(n_estimators=100, max_depth=6, random_state=42))\n",
    "adaboost_model =  make_pipeline(preprocessor, AdaBoostRegressor(learning_rate=0.1, random_state=42))\n",
    "\n",
    "# Cross-validation with R^2 score for each model\n",
    "models = {\n",
    "    'GradientBoost': gb_model,\n",
    "    'RandomForest': rf_model,\n",
    "    'AdaBoost': adaboost_model\n",
    "}\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tags({\"Model\":name, \"Train Data\": \"training-set\"})\n",
    "        mlflow.log_params({'cross_validation':5})\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=r2_scorer)\n",
    "        mlflow.log_metric(\"Mean R2 Score\", cv_scores.mean())\n",
    "    mlflow.end_run() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, in a real-world scenario, you wouldn't change your parameter values manually and re-run your code, you would either use a loop to loop through different parameter values, or you'd use a built-in method for doing cross-validation, of which there are a few. First, let's use a simple loop to run the experiment multiple times, and save the results of each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.05, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5797279  0.47611293 0.64536234 0.4247842  0.52691693]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.05, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57032164 0.47910052 0.65317386 0.41155257 0.52817611]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.05, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56567861 0.479377   0.64487676 0.44558909 0.52319222]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.05, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56287443 0.53277507 0.64730981 0.42830983 0.53541462]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.1, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56396375 0.46377358 0.65017825 0.39611203 0.52093381]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.1, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57756467 0.46266536 0.64289419 0.45058399 0.55207997]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.1, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57543452 0.46901278 0.61221715 0.37742902 0.51419726]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.1, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59172041 0.46513911 0.62501877 0.39358241 0.50438949]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.01, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.50977202 0.46194792 0.578821   0.37583802 0.49042714]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.01, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.51093912 0.46476216 0.5791962  0.3702907  0.48722907]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.01, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.53672452 0.46467974 0.6071488  0.41473746 0.50545442]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.01, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54405826 0.46510361 0.60783476 0.41377395 0.50729156]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.08, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56097746 0.50766735 0.64795825 0.43154239 0.53343637]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.08, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58296445 0.51460097 0.65164749 0.39896732 0.5240664 ]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.08, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58838469 0.49871785 0.61576019 0.43083424 0.53091628]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.08, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58279415 0.47810487 0.63484964 0.44099355 0.53879613]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.09, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58037439 0.50440371 0.67159649 0.43282279 0.52980719]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.09, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58567875 0.51208305 0.66635795 0.4119803  0.5329285 ]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.09, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57347    0.48574499 0.61053555 0.34366767 0.49784493]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.09, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58512163 0.46650343 0.61328069 0.3648706  0.52355287]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.07, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56521357 0.50431151 0.64013684 0.42340968 0.54466686]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.07, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57306066 0.50264053 0.65644114 0.44311967 0.52792857]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.07, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59398948 0.51173323 0.62310222 0.44090829 0.52551956]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.07, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5718575  0.50592064 0.62205109 0.43728334 0.5286254 ]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.06, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57513913 0.46060881 0.65003721 0.43727327 0.52865229]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.06, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57229136 0.49590775 0.64839526 0.4148071  0.5347888 ]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.06, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56559327 0.52014328 0.62789286 0.41994419 0.53486325]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.06, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56175829 0.48831379 0.61961539 0.43872249 0.52665526]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.12, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57986767 0.47430356 0.63335351 0.45206335 0.52251736]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.12, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59523486 0.47984283 0.62150329 0.44682058 0.54067315]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.12, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54629063 0.48186263 0.60247128 0.37575483 0.5291421 ]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.12, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.55464933 0.48938369 0.59115783 0.35127068 0.52476274]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.15, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57516364 0.47889332 0.60006528 0.37975992 0.51514538]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.15, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5591599  0.44835626 0.60350081 0.37309936 0.49654162]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.15, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54354871 0.45372474 0.61388696 0.31736838 0.51339139]\n",
      "Gradient boosting with parameters n_estimators=300, learning_rate=0.15, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54060076 0.46096965 0.60113649 0.3090844  0.50321737]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.05, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58627482 0.47713755 0.64810404 0.42710899 0.51765585]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.05, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57414641 0.47317774 0.65907473 0.40222308 0.52062117]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.05, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56887735 0.47901673 0.64546481 0.44534008 0.520836  ]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.05, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5664761  0.53538532 0.6467399  0.43000441 0.53796779]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.1, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56257824 0.46304637 0.64830107 0.39163771 0.52244237]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.1, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57567876 0.45869575 0.64772871 0.44272295 0.5446821 ]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.1, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57531023 0.46935159 0.61162011 0.3750531  0.51554211]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.1, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59038638 0.46691602 0.62601889 0.38874139 0.50352551]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.01, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.52994615 0.47151508 0.59897712 0.39668443 0.50519302]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.01, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.53082447 0.47584347 0.59858077 0.39401994 0.50358891]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.01, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54983565 0.47436639 0.61900698 0.4276612  0.51830038]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.01, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.55944237 0.47414217 0.62076269 0.42777286 0.51897897]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.08, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57032562 0.50876696 0.64888765 0.43028357 0.53515144]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.08, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58678928 0.51498835 0.64977579 0.39977753 0.52227329]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.08, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58875899 0.49936955 0.61503471 0.43244735 0.53040065]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.08, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58242179 0.48261836 0.63830447 0.43965038 0.53490973]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.09, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58305717 0.50590536 0.67127705 0.43713941 0.52502832]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.09, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59006797 0.5055217  0.6718993  0.41305973 0.52463862]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.09, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5734252  0.48821964 0.61109513 0.3417851  0.49789183]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.09, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58328651 0.46988411 0.61325219 0.36420023 0.5224685 ]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.07, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56933931 0.49723981 0.64738806 0.41969577 0.53761971]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.07, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5749557  0.50500581 0.65894402 0.44414207 0.52539787]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.07, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59447047 0.51470323 0.62333385 0.4389539  0.52405943]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.07, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57207168 0.5061959  0.62496132 0.43487125 0.52835279]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.06, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57937076 0.45180618 0.65130494 0.44235919 0.52197546]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.06, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57100295 0.49407896 0.65546371 0.41684508 0.53154379]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.06, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56566985 0.52177297 0.62993932 0.41928338 0.53531745]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.06, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56057077 0.48857101 0.62106004 0.4414192  0.52772013]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.12, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58249759 0.47138674 0.63653465 0.45071062 0.51471711]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.12, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59370223 0.47554457 0.62227859 0.45122325 0.53682367]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.12, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54694439 0.48277436 0.60338871 0.37640968 0.52799416]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.12, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.55369332 0.49053281 0.59086607 0.34729729 0.52370654]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.15, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57416297 0.47869834 0.60297405 0.36804497 0.51453765]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.15, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.55914836 0.44641142 0.60673336 0.3708041  0.49741539]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.15, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5424491  0.45496708 0.61381731 0.31695998 0.51244003]\n",
      "Gradient boosting with parameters n_estimators=400, learning_rate=0.15, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54095201 0.46151822 0.6015034  0.30527425 0.50185705]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.05, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5853232  0.48166924 0.65408959 0.42096801 0.51340043]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.05, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57017185 0.47778717 0.66217963 0.39300548 0.51478811]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.05, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56797924 0.47965117 0.6458112  0.44281605 0.51887997]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.05, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56825524 0.5384049  0.64803285 0.42728312 0.53598495]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.1, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56168462 0.45649213 0.65252625 0.38598065 0.52088256]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.1, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57456697 0.45904776 0.64692378 0.43431018 0.54154577]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.1, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57509575 0.46926534 0.61191147 0.37477974 0.51566112]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.1, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59095613 0.4677002  0.62495129 0.38822515 0.50300919]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.01, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54455594 0.47493734 0.61210005 0.40818312 0.51868399]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.01, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54242932 0.48075331 0.61193004 0.40483501 0.51675777]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.01, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.55794431 0.48032655 0.62766945 0.43522462 0.52355577]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.01, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56780991 0.48029001 0.63143261 0.43430927 0.52723433]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.08, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5669656  0.50705969 0.64860868 0.42639656 0.53008929]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.08, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58280785 0.51336579 0.65344811 0.39096319 0.52271995]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.08, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58686439 0.49944827 0.61538279 0.43306235 0.52840064]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.08, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58142094 0.48422549 0.63857302 0.43740839 0.53386295]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.09, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58219608 0.5058123  0.67085697 0.43027484 0.52604247]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.09, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58583382 0.50777481 0.67068257 0.40876993 0.523759  ]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.09, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.5736528  0.48914435 0.61139573 0.34273429 0.4974718 ]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.09, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58357768 0.46855116 0.61309897 0.36441701 0.52115841]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.07, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56722676 0.49539305 0.65440293 0.40403786 0.53478027]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.07, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57166043 0.50600572 0.66000004 0.43316958 0.52385284]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.07, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.59362287 0.51593689 0.62276203 0.43582295 0.52283799]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.07, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56992752 0.50849837 0.62518112 0.43234452 0.52930469]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.06, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57614179 0.45224609 0.6560935  0.4455682  0.52011792]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.06, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57287462 0.49083735 0.65896843 0.41364395 0.52769985]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.06, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56506922 0.52368354 0.63139313 0.41970435 0.53543523]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.06, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.56094859 0.49104493 0.62165827 0.43822955 0.52702565]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.12, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57812316 0.47191655 0.63667679 0.45138535 0.51282635]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.12, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58979876 0.46985293 0.62242531 0.44998581 0.53295197]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.12, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54730831 0.48344302 0.60357566 0.3754898  0.52681407]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.12, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.55366355 0.49107016 0.59015662 0.34779506 0.52366234]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.15, max_depth=3,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.57474124 0.47741855 0.60295545 0.36267825 0.51230055]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.15, max_depth=3,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.55534838 0.44640101 0.60742183 0.37327548 0.49512981]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.15, max_depth=5,                                    min_samples_split=5,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.542665   0.45567579 0.61397108 0.31785208 0.51222245]\n",
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.15, max_depth=5,                                    min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.54131797 0.46153803 0.60129631 0.3044225  0.50175105]\n"
     ]
    }
   ],
   "source": [
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'learning_rate': [0.05, 0.1, 0.01, 0.08, 0.09, 0.07, 0.06,0.12, 0.15],\n",
    "    'max_depth': [3, 5],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'subsample': [0.6],\n",
    "    'random_state': [42]\n",
    "}\n",
    "best_r2 = 0\n",
    "for est in param_grid[\"n_estimators\"]:\n",
    "    for lr in param_grid[\"learning_rate\"]:\n",
    "        for md in param_grid[\"max_depth\"]:\n",
    "            for ss in param_grid[\"min_samples_split\"]:\n",
    "                        for sbs in param_grid[\"subsample\"]:\n",
    "                            with mlflow.start_run():\n",
    "                                mlflow.set_tags({\"Model\":\"GradientBoost\", \"Train Data\": \"training-set\"})\n",
    "                                mlflow.log_params({'n_estimators':est, 'learning_rate':lr,'max_depth':md, 'min_samples_split':ss, 'subsample':sbs})\n",
    "                                gb_model = make_pipeline(preprocessor, GradientBoostingRegressor(n_estimators=est, learning_rate=lr, max_depth=md,\n",
    "                                                                                                min_samples_split=ss,\n",
    "                                                                                                random_state=42, subsample=sbs))\n",
    "                                cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5, scoring=r2_scorer)\n",
    "                                print(f\"Gradient boosting with parameters n_estimators={est}, learning_rate={lr}, max_depth={md},\\\n",
    "                                    min_samples_split={ss},max_features={mf}, subsample={sbs} Cross-Validation R^2 Scores:\", cv_scores)\n",
    "                                mlflow.log_metric(\"Mean R2 Score\", cv_scores.mean())\n",
    "                            mlflow.end_run()\n",
    "                                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifact Tracking and Model Registry (Local)\n",
    "\n",
    "In this section we will save some artifacts from our model as we go through the model development process. There are a few things that might be worth saving, such as datasets, plots, and the final model itself that might go into production later.\n",
    "\n",
    "## Data\n",
    "\n",
    "First, let's see how we can store our important datasets, in a compressed format, for use for later, for example, in case we get a new request about our model and need to run some analyses (such as \"what is the distribution of this feature, but only for this specific subset of data?\" or \"how did the model do on these particular observations from your validation set?\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting with parameters n_estimators=500, learning_rate=0.15, max_depth=5,        min_samples_split=10,max_features=auto, subsample=0.6 Cross-Validation R^2 Scores: [0.58305717 0.50590536 0.67127705 0.43713941 0.52502832]\n"
     ]
    }
   ],
   "source": [
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tags({\"Model\":\"GradientBoost\", \"Train Data\": \"training-set\"})\n",
    "    mlflow.log_params({'n_estimators':400, 'learning_rate':0.09,'max_depth':3, 'min_samples_split':5, 'subsample':0.6, 'cross_validation':5})\n",
    "    gb_model = make_pipeline(preprocessor, GradientBoostingRegressor(n_estimators=400, learning_rate=0.09, max_depth=3,\n",
    "                                                                    min_samples_split=5,\n",
    "                                                                    random_state=42, subsample=0.6))\n",
    "    cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5, scoring=r2_scorer)\n",
    "    print(f\"Gradient boosting with parameters n_estimators={est}, learning_rate={lr}, max_depth={md},\\\n",
    "        min_samples_split={ss},max_features={mf}, subsample={sbs} Cross-Validation R^2 Scores:\", cv_scores)\n",
    "    mlflow.log_metric(\"Mean R2 Score\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.makedirs('save_data', exist_ok = True)\n",
    "\n",
    "X_train.to_parquet('save_data/x_train.parquet')\n",
    "pd.DataFrame(y_train).to_parquet('save_data/y_train.parquet')\n",
    "mlflow.log_artifact('save_data/x_train.parquet')\n",
    "mlflow.log_artifact('save_data/y_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_parquet('save_data/x_test.parquet')\n",
    "\n",
    "mlflow.log_artifact('save_data/x_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "os.makedirs('../models', exist_ok = True)\n",
    "\n",
    "with open('../models/model.pkl','wb') as f:\n",
    "    pickle.dump(gb_model,f)\n",
    "\n",
    "# First we'll log the model as an artifact\n",
    "mlflow.log_artifact('../models/model.pkl', artifact_path='my_models')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging as a Model\n",
    "\n",
    "Logging the model as an artifact only logs the pickle file (the serialized version of the model). It's not really very useful, especially since models contain so much metadata that might be critical to know for deploying the model later. mlflow has a built-in way of logging models specifically, so let's see how to use this, and how it's different from logging models as an artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 20:35:20 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "# Let's do it again, but this time we will log the model using log_model\n",
    "mlflow.sklearn.log_model(gb_model, artifact_path = 'better_models')\n",
    "mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models\n",
    "\n",
    "Now that models have been logged, you can load specific models back into python for predicting and further analysis. There are two main ways to do this. The mlflow UI actually gives you some instructions, with code that you copy and paste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: better_models\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: 6e609e69e44a452781beff60f3502547"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = 'runs:/6e609e69e44a452781beff60f3502547/better_models' #replace with one of your models\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;tfidf_title&#x27;,\n",
       "                                                  TfidfVectorizer(), &#x27;title&#x27;),\n",
       "                                                 (&#x27;tfidf_desc&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;desc&#x27;)])),\n",
       "                (&#x27;gradientboostingregressor&#x27;,\n",
       "                 GradientBoostingRegressor(learning_rate=0.09,\n",
       "                                           min_samples_split=5,\n",
       "                                           n_estimators=400, random_state=42,\n",
       "                                           subsample=0.6))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;tfidf_title&#x27;,\n",
       "                                                  TfidfVectorizer(), &#x27;title&#x27;),\n",
       "                                                 (&#x27;tfidf_desc&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;desc&#x27;)])),\n",
       "                (&#x27;gradientboostingregressor&#x27;,\n",
       "                 GradientBoostingRegressor(learning_rate=0.09,\n",
       "                                           min_samples_split=5,\n",
       "                                           n_estimators=400, random_state=42,\n",
       "                                           subsample=0.6))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;columntransformer: ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for columntransformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;tfidf_title&#x27;, TfidfVectorizer(), &#x27;title&#x27;),\n",
       "                                (&#x27;tfidf_desc&#x27;, TfidfVectorizer(), &#x27;desc&#x27;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">tfidf_title</label><div class=\"sk-toggleable__content \"><pre>title</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content \"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">tfidf_desc</label><div class=\"sk-toggleable__content \"><pre>desc</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content \"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">remainder</label><div class=\"sk-toggleable__content \"><pre></pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">passthrough</label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content \"><pre>GradientBoostingRegressor(learning_rate=0.09, min_samples_split=5,\n",
       "                          n_estimators=400, random_state=42, subsample=0.6)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf_title',\n",
       "                                                  TfidfVectorizer(), 'title'),\n",
       "                                                 ('tfidf_desc',\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  'desc')])),\n",
       "                ('gradientboostingregressor',\n",
       "                 GradientBoostingRegressor(learning_rate=0.09,\n",
       "                                           min_samples_split=5,\n",
       "                                           n_estimators=400, random_state=42,\n",
       "                                           subsample=0.6))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model = mlflow.sklearn.load_model(logged_model)\n",
    "sklearn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([351227.86924396, 341710.04607325, 290986.67943832, 374140.77610102,\n",
       "       344945.10384913])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.fit(X_train, y_train)\n",
    "preds = sklearn_model.predict(X_test)\n",
    "preds[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Registry\n",
    "\n",
    "Typically, you will **register** your *chosen* model, the model you plan to put into production. But, sometimes, after you've chosen and registered a model, you may need to replace that model with a new version. For example, the model may have gone into production and started to degrade in performance, and so the model needed to be retrained. Or, you go to deploy your model and notice an error or bug, and now have to go back and retrain it.\n",
    "\n",
    "In this section let's see how we take our logged models and register them in the model registry, which then can get picked up by the production process, or engineer, for deployment. First, I'll demonstrate how this is done within the UI, but then below I'll show how we can use the python API to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Price_prediction'.\n",
      "Created version '1' of model 'Price_prediction'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1725334604027, current_stage='None', description=None, last_updated_timestamp=1725334604027, name='Price_prediction', run_id='6e609e69e44a452781beff60f3502547', run_link=None, source='/Users/tatshini/USF_School/DE/mlops/insyd_mlops/mlruns/1/6e609e69e44a452781beff60f3502547/artifacts/artifacts/better_models', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runid = '6e609e69e44a452781beff60f3502547'\n",
    "mod_path = f'runs:/{runid}/artifacts/better_models'\n",
    "mlflow.register_model(model_uri = mod_path, name = 'Price_prediction')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Experiment Tracking and Model Registry Lab\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab you will each download a new dataset and attempt to train a good model, and use mlflow to keep track of all of your experiments, log your metrics, artifacts and models, and then register a final set of models for \"deployment\", though we won't actually deploy them anywhere yet.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Your goal is **not** to become a master at MLFlow - this is not a course on learning all of the ins and outs of MLFlow. Instead, your goal is to understand when and why it is important to track your model development process (tracking experiments, artifacts and models) and to get into the habit of doing so, and then learn at least the basics of how MLFlow helps you do this so that you can then compare with other tools that are available.\n",
    "\n",
    "## Data\n",
    "\n",
    "You can choose your own dataset to use here. It will be helpful to choose a dataset that is already fairly clean and easy to work with. You can even use a dataset that you've used in a previous course. We will do a lot of labs where we do different things with datasets, so if you can find one that is interesting enough for modeling, it should work for most of the rest of the course. \n",
    "\n",
    "There are tons of places where you can find open public datasets. Choose something that interests you, but don't overthink it.\n",
    "\n",
    "[Kaggle Datasets](https://www.kaggle.com/datasets)  \n",
    "[HuggingFace Datasets](https://huggingface.co/docs/datasets/index)  \n",
    "[Dagshub Datasets](https://dagshub.com/datasets/)  \n",
    "[UCI](https://archive.ics.uci.edu/ml/datasets.php)  \n",
    "[Open Data on AWS](https://registry.opendata.aws/)  \n",
    "[Yelp](https://www.yelp.com/dataset)  \n",
    "[MovieLens](https://grouplens.org/datasets/movielens/)  \n",
    "And so many more...\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Once you have selected a set of data, create a brand new experiment in MLFlow and begin exploring your data. Do some EDA, clean up, and learn about your data. You do not need to begin tracking anything yet, but you can if you want to (e.g. you can log different versions of your data as you clean it up and do any feature engineering). Do not spend a ton of time on this part. Your goal isn't really to build a great model, so don't spend hours on feature engineering and missing data imputation and things like that.\n",
    "\n",
    "Once your data is clean, begin training models and tracking your experiments. If you intend to use this same dataset for your final project, then start thinking about what your model might look like when you actually deploy it. For example, when you engineer new features, be sure to save the code that does this, as you will need this in the future. If your final model has 1000 complex features, you might have a difficult time deploying it later on. If your final model takes 15 minutes to train, or takes a long time to score a new batch of data, you may want to think about training a less complex model.\n",
    "\n",
    "At a minimum, you should:\n",
    "\n",
    "1. Try at least 3 different ML algorithms.\n",
    "2. Do hyperparameter tuning for each model.\n",
    "3. Do some basic feature selection, and repeat the above steps with these reduced sets of features.\n",
    "4. Identify the top 3 best models and note these down for later.\n",
    "6. Choose the **final** model you want to deploy and stage it (in MLFlow) and run it on the test set to get a final measure of performance.\n",
    "7. Log the exact training, validation, and testing datasets for the 3 best models, as well as hyperparameter values, and the values of your metrics.  \n",
    "8. Push your code to Github. No need to track the mlruns folder, the images folder, any datasets, or the sqlite database in git.\n",
    "\n",
    "### Turning It In\n",
    "\n",
    "In the MLFlow UI, next to the refresh button you should see three vertical dots. Click the dots and then download your experiments as a csv file. Open the csv file and highlight the rows for your top 3 models from step 4 above and then save as an excel file. Take a snapshot of the Models page in the MLFLow UI showing the model you staged in step 6 above. Submit the excel file and snapshot to Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3882342cd29dc00050ef2e20dd83534c2e4935240c65c7613c384f58dc6265d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
